{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8db18d1",
   "metadata": {},
   "source": [
    "### Packages Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920203c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23eb935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,minmax_scale\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from skimage import feature,data,io,measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "295f8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random\n",
    "import itertools\n",
    "import keras\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from keras import applications\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense,Activation,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator,image_utils\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint,Callback,EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d919b",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcc30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 70\n",
    "batch_size_val = 5\n",
    "batch_size_test = 5\n",
    "num_classes= 5\n",
    "STANDARD_SIZE=(224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72f481",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ea4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "img_class = ['Cheque','Documents','Driving_License','Pancard','Passport']\n",
    "datagen = ImageDataGenerator(data_format = k.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e19248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/'\n",
    "train_img = ImageDataGenerator().flow_from_directory(path+'Train_Data',target_size=(224,224),classes=img_class,batch_size=batch_size_train)\n",
    "type(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7bf2a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = ImageDataGenerator().flow_from_directory(path+'Test_Data',target_size=(224,224),classes=img_class,batch_size=batch_size_test)\n",
    "type(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "866f1a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_img = ImageDataGenerator().flow_from_directory(path+'Val_Data',target_size=(224,224),classes=img_class,batch_size=batch_size_val)\n",
    "type(val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b532d7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_shape :  (70, 224, 224, 3)\n",
      "labels_shape :  (70, 5)\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_imgs,train_labels = next(train_img)\n",
    "print('images_shape : ',train_imgs.shape)\n",
    "print('labels_shape : ',train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afa54712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_shape :  (5, 224, 224, 3)\n",
      "labels_shape :  (5, 5)\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "test_imgs,test_labels = next(test_img)\n",
    "print('images_shape : ',test_imgs.shape)\n",
    "print('labels_shape : ',test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfe0ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_shape :  (5, 224, 224, 3)\n",
      "labels_shape :  (5, 5)\n"
     ]
    }
   ],
   "source": [
    "#val\n",
    "val_imgs,val_labels = next(val_img)\n",
    "print('images_shape : ',val_imgs.shape)\n",
    "print('labels_shape : ',val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c0e21",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c57d49ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 123s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M_vgg = keras.applications.vgg16.VGG16()\n",
    "M_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e1a6efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1c602b77be0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602b771f0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602b807c0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1c602b92040>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602b85610>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602bb1be0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1c602bb8850>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602bb1070>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602c39220>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602c3abe0>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1c602c3c850>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602b9a820>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602c3d910>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602bb8880>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1c602bae520>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602bae4c0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602c49310>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1c602bc2b50>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1c602c39280>,\n",
       " <keras.layers.reshaping.flatten.Flatten at 0x1c602c07d60>,\n",
       " <keras.layers.core.dense.Dense at 0x1c602c498b0>,\n",
       " <keras.layers.core.dense.Dense at 0x1c602c4aac0>,\n",
       " <keras.layers.core.dense.Dense at 0x1c602c491f0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_vgg.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2ca8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = Sequential()\n",
    "for layer in M_vgg.layers:\n",
    "    M0.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70ae05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1aef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in M0.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30f3decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M0.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "331cf095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,362,549\n",
      "Trainable params: 5,005\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25c76dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "M0.compile(Adam(learning_rate=0.00015),loss=keras.losses.categorical_crossentropy,metrics=keras.metrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fa0aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin\\AppData\\Local\\Temp/ipykernel_20788/1574379237.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  M0.fit_generator(train_img,validation_data=val_img,epochs=5, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.5994 - accuracy: 0.0000e+00 - val_loss: 1.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.5993 - accuracy: 0.0000e+00 - val_loss: 1.5976 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.5992 - accuracy: 0.0000e+00 - val_loss: 1.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.5991 - accuracy: 0.0000e+00 - val_loss: 1.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 11s 11s/step - loss: 1.5991 - accuracy: 0.0000e+00 - val_loss: 1.5973 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c601a81970>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M0.fit_generator(train_img,validation_data=val_img,epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M0.save_weights('M0.h5')\n",
    "#M0.load_weights('M0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f217d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,362,549\n",
      "Trainable params: 5,005\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c250f37",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c4048af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8546ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [test_path+\"/cheque copy 2.jpg\", test_path+\"/driving_license_2 copy 2.jpg\",test_path+\"/Form1 copy 2.jpg\", test_path+\"/pan copy 2.jpg\", test_path+\"/passport copy 2.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d13c5ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/cheque copy 2.jpg',\n",
       " 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/driving_license_2 copy 2.jpg',\n",
       " 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/Form1 copy 2.jpg',\n",
       " 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/pan copy 2.jpg',\n",
       " 'C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/passport copy 2.jpg']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d9b3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "def convert_to_image(X):\n",
    "    '''Function to convert all Input Images to the STANDARD_SIZE and create Training Dataset\n",
    "    '''\n",
    "    for f in paths:\n",
    "        #fobj=get_file(f)\n",
    "        #print(type(fobj))predictions= model.predict(X_test)\n",
    "        if os.path.isdir(f):\n",
    "            continue\n",
    "        img= PIL.Image.open(f)\n",
    "        img = img.resize(STANDARD_SIZE)\n",
    "        img= np.array(img)\n",
    "        X.append(img)\n",
    "        #print(X_train)\n",
    "    #print(len(X_train))\n",
    "    return X\n",
    "test_x=np.array(convert_to_image(test_x))\n",
    "datagen.fit(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5caf382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "pred = M0.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ee29dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = []\n",
    "for i in range(len(pred)):\n",
    "    test_y.append(np.argmax(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9249eac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 3, 4, 4]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4231cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/pan copy 2.jpg\n",
      "C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/passport copy 2.jpg\n",
      "C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/pan copy 2.jpg\n",
      "C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/passport copy 2.jpg\n",
      "C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/passport copy 2.jpg\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in test_y:\n",
    "    print(paths[test_y[j]])\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d781f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classified as a Passport document:  C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/driving_license_2 copy 2.jpg\n",
      "Image classified as a Passport document:  C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/pan copy 2.jpg\n",
      "Image classified as a Passport document:  C:/Users/Nithin/Downloads/Image classification_AI_Transfer Learn/Datasets/Ext_Test/passport copy 2.jpg\n"
     ]
    }
   ],
   "source": [
    "#print(classes_required)\n",
    "index = img_class.index('Passport')\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == index:\n",
    "        print(\"Image classified as a Passport document: \", paths[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
